# FBI: Các quan chức Mỹ bị nhắm mục tiêu trong các cuộc tấn công deepfake giọng nói từ tháng Tư

![FBI](https://www.bleepstatic.com/content/hl-images/2025/04/23/FBI.jpg)

FBI đã cảnh báo rằng các tội phạm mạng sử dụng deepfake âm thanh được tạo ra bởi AI để nhắm mục tiêu vào các quan chức Mỹ trong các cuộc tấn công phishing qua giọng nói bắt đầu từ tháng Tư.

Cảnh báo này là một phần của thông báo dịch vụ công được phát hành vào thứ Năm, cũng cung cấp các biện pháp giảm thiểu để giúp công chúng phát hiện và chặn các cuộc tấn công sử dụng deepfake âm thanh (còn được gọi là deepfake giọng nói).

"Kể từ tháng Tư năm 2025, các tác nhân độc hại đã giả mạo các quan chức cấp cao của Mỹ để nhắm mục tiêu vào các cá nhân, nhiều người trong số họ là các quan chức cấp cao liên bang hoặc tiểu bang của Mỹ hiện tại hoặc trước đây và các liên hệ của họ. Nếu bạn nhận được tin nhắn tuyên bố là từ một quan chức cấp cao của Mỹ, đừng giả định rằng nó là xác thực," FBI cảnh báo.

"Các tác nhân độc hại đã gửi tin nhắn văn bản và tin nhắn giọng nói được tạo ra bởi AI - các kỹ thuật được biết đến với tên gọi smishing và vishing, tương ứng - tuyên bố đến từ một quan chức cấp cao của Mỹ trong nỗ lực thiết lập mối quan hệ trước khi tiếp cận vào các tài khoản cá nhân."

Các kẻ tấn công có thể truy cập vào các tài khoản của các quan chức Mỹ bằng cách gửi các liên kết độc hại được ngụy trang thành các liên kết được thiết kế để chuyển cuộc thảo luận sang một nền tảng nhắn tin khác.

Bằng cách xâm phạm các tài khoản của họ, các tác nhân đe dọa có thể truy cập vào thông tin liên lạc của các quan chức chính phủ khác. Sau đó, họ có thể sử dụng kỹ thuật social engineering để giả mạo các quan chức Mỹ đã bị xâm phạm để đánh cắp thông tin nhạy cảm khác và đánh lừa các liên hệ được nhắm mục tiêu chuyển tiền.

Thông báo dịch vụ công hôm nay theo sau một Thông báo ngành tư nhân của FBI vào tháng Ba năm 2021 (PIN) \[[PDF](https://www.ic3.gov/Media/News/2021/210310-2.pdf)\] cảnh báo rằng deepfake (bao gồm âm thanh, văn bản, hình ảnh hoặc video được tạo ra hoặc thao túng bởi AI) có khả năng sẽ được sử dụng rộng rãi trong "các hoạt động mạng và ảnh hưởng nước ngoài" sau khi trở nên ngày càng tinh vi.

Một năm sau, Europol [đã cảnh báo](http://www.europol.europa.eu/media-press/newsroom/news/europol-report-finds-deepfake-technology-could-become-staple-tool-for-organised-crime) rằng deepfake có thể sớm trở thành một công cụ mà các nhóm tội phạm mạng có thể sử dụng thường xuyên trong gian lận CEO, việc tạo ra khiêu dâm không đồng thuận và thao túng chứng cứ.

[Department of Health and Human Services (HHS) của Mỹ](https://www.bleepingcomputer.com/news/security/us-health-dept-warns-hospitals-of-hackers-targeting-it-help-desks/) cũng đã cảnh báo vào tháng Tư năm 2024 rằng các tội phạm mạng đang nhắm mục tiêu vào các bàn hỗ trợ IT trong các cuộc tấn công social engineering sử dụng AI voice cloning để đánh lừa các mục tiêu.

Cuối tháng đó, LastPass tiết lộ rằng các kẻ tấn công chưa rõ danh tính [đã sử dụng âm thanh deepfake để giả mạo Karim Toubba](https://www.bleepingcomputer.com/news/security/lastpass-hackers-targeted-employee-in-failed-deepfake-ceo-call/) , Giám đốc điều hành của công ty, trong một cuộc tấn công phishing qua giọng nói nhắm vào một trong những nhân viên của mình.